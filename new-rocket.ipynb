{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca44a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb3c1a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_label(dataset): \n",
    "    \n",
    "\n",
    "    df = pd.read_csv(dataset)\n",
    "    alpha = df['scp_codes'].str.split(\"'\").str[1].str[-2:]=='MI'  \n",
    "    beta = df['scp_codes'].str.split(\"'\").str[1]=='NORM'       \n",
    "    df = df[alpha|beta]\n",
    "    df['label'] = df['scp_codes'].str.split(\"'\").str[1]      \n",
    "      \n",
    "    inst_c1 = df[df['label'] == 'NORM']\n",
    "    inst_c1 = inst_c1.sample(n = 1000, random_state = 1)\n",
    "    \n",
    "#     inst_c2 = df[df['label'] == 'ALMI']\n",
    "#     inst_c2 = inst_c2.sample(n = 164, random_state = 1)\n",
    "\n",
    "    inst_c3 = df[df['label'] == 'ILMI']\n",
    "    inst_c3 = inst_c3.sample(n = 393, random_state = 1)\n",
    "\n",
    "    df_new = pd.concat([inst_c1, inst_c3], ignore_index = True)\n",
    "    df_new = df_new.sample(frac = 1, random_state=42)\n",
    "    \n",
    "    return  df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097bdb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_and_label(dataframe):  \n",
    "    \n",
    "    X = dataframe[['ecg_id', 'filename_hr']]   \n",
    "    X = X.to_numpy()\n",
    "    y = dataframe['label']\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    encoded_y = encoder.transform(y)\n",
    "    \n",
    "    return (X, encoded_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9321d99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1393,)\n",
      "(1393,)\n"
     ]
    }
   ],
   "source": [
    "alpha = collect_and_label(\"C:/Users/Pushpam/Downloads/ptbxl_database.csv\")  \n",
    "gamma0, gamma1 = div_and_label(alpha)\n",
    "gamma0 = gamma0[:,1]\n",
    "\n",
    "print(gamma0.shape)\n",
    "print(gamma1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bc1ccf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_data = gamma1;\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e114a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import butter, filtfilt, detrend\n",
    "\n",
    "directory = 'D:/Internship/MIDataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1'\n",
    "\n",
    "X = []\n",
    "for itr in range(gamma0.shape[0]):\n",
    "    record_name = str(gamma0[itr])\n",
    "    \n",
    "    signal, meta_val = wfdb.rdsamp(directory + '/' + record_name)\n",
    "    value = signal.T\n",
    "    ecg_signals = value\n",
    "\n",
    "    X.append(detrend(ecg_signals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39fc782",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "685442d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # windowing X in xnew\n",
    "# xnew = []\n",
    "# ynew = []\n",
    "# patient_ids = []\n",
    "# for i in range(964):\n",
    "#     xnew.append(X[i,:,0:1000])\n",
    "#     xnew.append(X[i,:,1000:2000])\n",
    "#     xnew.append(X[i,:,2000:3000])\n",
    "#     xnew.append(X[i,:,3000:4000])\n",
    "#     xnew.append(X[i,:,4000:5000])\n",
    "#     for j in range(5):\n",
    "#         ynew.append(y_data[i])\n",
    "#         patient_ids.append(i)\n",
    "# patient_ids = np.array(patient_ids)\n",
    "\n",
    "\n",
    "xnew = []\n",
    "ynew = []\n",
    "patient_ids = []\n",
    "window_size = 1000  \n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(5):  \n",
    "        start = j * window_size\n",
    "        end = (j + 1) * window_size\n",
    "        xnew.append(X[i, :, start:end])\n",
    "        ynew.append(y_data[i]) \n",
    "        patient_ids.append(i)\n",
    "\n",
    "xnew = np.array(xnew)\n",
    "ynew = np.array(ynew)\n",
    "patient_ids = np.array(patient_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7919337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "160b6ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rocket=Rocket()\n",
    "rocket=Rocket(num_kernels=1000)\n",
    "rocket.fit(xnew)\n",
    "xt=rocket.transform(xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4367481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(r\"xt_ILMI_1000+393_kernels1000.npy\", xt)\n",
    "# np.save(r\"ynew_ILMI_1000+393_kernels1000.npy\", ynew)\n",
    "# np.save(r\"patient_ids_ILMI_1000+393_kernels1000.npy\",patient_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cc12337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xt = np.load(r\"xt_ALMI_800+164_kernels5000.npy\")\n",
    "# ynew = np.load(r\"ynew_ALMI_800+164_kernels5000.npy\")\n",
    "# patient_id = np.load(r\"patient_id_ILMI_1000+393.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb299e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.load(\"xt_ILMI_1000+393_kernels2000.npy\")\n",
    "ynew = np.load(\"ynew_ILMI_1000+393_kernels2000.npy\")\n",
    "patient_ids = np.load(\"patient_ids_ILMI_1000+393_kernels2000.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "277d7052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6965, 4000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "477e3914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6965, 2576)\n"
     ]
    }
   ],
   "source": [
    "xt = np.concatenate((xt,all_features),axis=1)\n",
    "print(xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb0f2ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 74   8]\n",
      " [  1 196]]\n",
      "Accuracy: 0.967741935483871\n",
      "Sensitivity: 0.9949238578680203\n",
      "Specificity: 0.9024390243902439\n",
      "[[ 77   1]\n",
      " [  8 193]]\n",
      "Accuracy: 0.967741935483871\n",
      "Sensitivity: 0.9601990049751243\n",
      "Specificity: 0.9871794871794872\n",
      "[[ 84   1]\n",
      " [  6 188]]\n",
      "Accuracy: 0.974910394265233\n",
      "Sensitivity: 0.9690721649484536\n",
      "Specificity: 0.9882352941176471\n",
      "[[ 67   7]\n",
      " [  2 202]]\n",
      "Accuracy: 0.9676258992805755\n",
      "Sensitivity: 0.9901960784313726\n",
      "Specificity: 0.9054054054054054\n",
      "[[ 64  10]\n",
      " [  2 202]]\n",
      "Accuracy: 0.9568345323741008\n",
      "Sensitivity: 0.9901960784313726\n",
      "Specificity: 0.8648648648648649\n",
      "Average Accuracy: 0.9669709393775303\n",
      "Average Sensitivity: 0.9809174369308687\n",
      "Average Specificity: 0.9296248151915296\n",
      "Average F1-Score: 0.9771713231592762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "sum_accuracy = 0\n",
    "sum_sensitivity = 0\n",
    "sum_specificity = 0\n",
    "sum_f1 = 0\n",
    "\n",
    "for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "    X_train, X_test = xt[train_idx], xt[test_idx]\n",
    "    y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    y_pred_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_pred_majority.append(majority_vote)\n",
    "\n",
    "    y_test_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_test_majority.append(majority_vote)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "    sum_accuracy += accuracy\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_majority, y_pred_majority).ravel()\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1 = f1_score(y_test_majority, y_pred_majority)\n",
    "\n",
    "    sum_sensitivity += sensitivity\n",
    "    sum_specificity += specificity\n",
    "    sum_f1 += f1\n",
    "\n",
    "    print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "#     print(\"F1-Score:\", f1)\n",
    "#     print()\n",
    "\n",
    "average_accuracy = sum_accuracy / 5\n",
    "average_sensitivity = sum_sensitivity / 5\n",
    "average_specificity = sum_specificity / 5\n",
    "average_f1 = sum_f1 / 5\n",
    "\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "print(\"Average Sensitivity:\", average_sensitivity)\n",
    "print(\"Average Specificity:\", average_specificity)\n",
    "print(\"Average F1-Score:\", average_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c123590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.load('matrices_data.npz')\n",
    "cross_corr_loaded = loaded_data['cross_corr']\n",
    "coherence_loaded = loaded_data['coherence']\n",
    "pli_loaded = loaded_data['pli']\n",
    "plv_loaded = loaded_data['plv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d386a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = []\n",
    "for i in range(6965):\n",
    "    all_features.append(np.concatenate((cross_corr_loaded[i].ravel(),coherence_loaded[i].ravel(),pli_loaded[i].ravel(),plv_loaded[i].ravel()),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e693440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6965, 576)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a5dfdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.preprocessing import scale\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "# kf=KFold(n_splits=5,shuffle=True)\n",
    "# average = 0;\n",
    "# for tr_idx, test_idx in kf.split(xt):\n",
    "#     X_train, X_test=xt.iloc[tr_idx,:],xt.iloc[test_idx,:]\n",
    "#     y_train, y_test=ynew[tr_idx],ynew[test_idx]\n",
    "\n",
    "#     classifier=SGDClassifier()\n",
    "#     classifier.fit(X_train,y_train)\n",
    "\n",
    "#     ypred=classifier.predict(X_test)\n",
    "\n",
    "#     from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#     print(confusion_matrix(y_test,ypred))\n",
    "#     print('accuracy:', accuracy_score(y_test,ypred))\n",
    "#     average+=accuracy_score(y_test,ypred)\n",
    "# print('Avearge accuracy:', average/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b526de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('xt_100%_1140+360.npy',np.array(xt))\n",
    "# np.save('ynew_100%_1140+360.npy',np.array(ynew))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46e266f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 68  14]\n",
      " [  3 194]]\n",
      "Accuracy: 0.9390681003584229\n",
      "[[ 73   5]\n",
      " [  3 198]]\n",
      "Accuracy: 0.9713261648745519\n",
      "[[ 80   5]\n",
      " [  3 191]]\n",
      "Accuracy: 0.9713261648745519\n",
      "[[ 65   9]\n",
      " [  4 200]]\n",
      "Accuracy: 0.9532374100719424\n",
      "[[ 59  15]\n",
      " [  5 199]]\n",
      "Accuracy: 0.9280575539568345\n",
      "Average Accuracy: 0.9526030788272607\n",
      "Average Sensitivity: 0.9820529271770271\n",
      "Average Specificity: 0.8764035749688548\n",
      "Average F1-Score: 0.9676772006232678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "sum_accuracy = 0\n",
    "sum_sensitivity = 0\n",
    "sum_specificity = 0\n",
    "sum_f1 = 0\n",
    "\n",
    "for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "    X_train, X_test = xt[train_idx], xt[test_idx]\n",
    "    y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "    # Use a Random Forest classifier instead of SGDClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators=25, random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    y_pred_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_pred_majority.append(majority_vote)\n",
    "\n",
    "    y_test_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_test_majority.append(majority_vote)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "    sum_accuracy += accuracy\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_majority, y_pred_majority).ravel()\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1 = f1_score(y_test_majority, y_pred_majority)\n",
    "\n",
    "    sum_sensitivity += sensitivity\n",
    "    sum_specificity += specificity\n",
    "    sum_f1 += f1\n",
    "\n",
    "    print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "average_accuracy = sum_accuracy / 5\n",
    "average_sensitivity = sum_sensitivity / 5\n",
    "average_specificity = sum_specificity / 5\n",
    "average_f1 = sum_f1 / 5\n",
    "\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "print(\"Average Sensitivity:\", average_sensitivity)\n",
    "print(\"Average Specificity:\", average_specificity)\n",
    "print(\"Average F1-Score:\", average_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99b96321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 75   7]\n",
      " [  4 193]]\n",
      "Accuracy: 0.9605734767025089\n",
      "[[ 74   4]\n",
      " [  9 192]]\n",
      "Accuracy: 0.953405017921147\n",
      "[[ 83   2]\n",
      " [  5 189]]\n",
      "Accuracy: 0.974910394265233\n",
      "[[ 67   7]\n",
      " [  3 201]]\n",
      "Accuracy: 0.9640287769784173\n",
      "[[ 66   8]\n",
      " [  4 200]]\n",
      "Accuracy: 0.9568345323741008\n",
      "Average Accuracy: 0.9619504396482814\n",
      "Average Sensitivity: 0.9749664781405223\n",
      "Average Specificity: 0.9274239961184007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "sum_accuracy = 0\n",
    "sum_sensitivity = 0\n",
    "sum_specificity = 0\n",
    "sum_f1 = 0\n",
    "\n",
    "for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "    X_train, X_test = xt[train_idx], xt[test_idx]\n",
    "    y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "    # Use an SVM classifier instead of RandomForestClassifier\n",
    "    classifier = SVC(kernel='poly', random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    y_pred_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_pred_majority.append(majority_vote)\n",
    "\n",
    "    y_test_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_test_majority.append(majority_vote)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "    sum_accuracy += accuracy\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_majority, y_pred_majority).ravel()\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1 = f1_score(y_test_majority, y_pred_majority)\n",
    "\n",
    "    sum_sensitivity += sensitivity\n",
    "    sum_specificity += specificity\n",
    "    sum_f1 += f1\n",
    "\n",
    "    print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "average_accuracy = sum_accuracy / 5\n",
    "average_sensitivity = sum_sensitivity / 5\n",
    "average_specificity = sum_specificity / 5\n",
    "average_f1 = sum_f1 / 5\n",
    "\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "print(\"Average Sensitivity:\", average_sensitivity)\n",
    "print(\"Average Specificity:\", average_specificity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfefbfde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
