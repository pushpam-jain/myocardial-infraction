{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7690f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336d1fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_label(dataset): \n",
    "    \n",
    "\n",
    "    df = pd.read_csv(dataset)\n",
    "    alpha = df['scp_codes'].str.split(\"'\").str[1].str[-2:]=='MI'  \n",
    "    beta = df['scp_codes'].str.split(\"'\").str[1]=='NORM'       \n",
    "    df = df[alpha|beta]\n",
    "    df['label'] = df['scp_codes'].str.split(\"'\").str[1]      \n",
    "      \n",
    "    inst_c1 = df[df['label'] == 'NORM']\n",
    "    inst_c1 = inst_c1.sample(n = 4500, random_state = 1)\n",
    "    \n",
    "    inst_c2 = df[df['label'] == 'IMI']\n",
    "    inst_c2 = inst_c2.sample(n = 1500, random_state = 1)\n",
    "    \n",
    "\n",
    "    df_new = pd.concat([inst_c1, inst_c2], ignore_index = True)\n",
    "    df_new = df_new.sample(frac = 1, random_state=42)\n",
    "    \n",
    "    return  df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "125817a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_and_label(dataframe):  \n",
    "    \n",
    "    X = dataframe[['ecg_id', 'filename_hr']]   \n",
    "    X = X.to_numpy()\n",
    "    y = dataframe['label']\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    encoded_y = encoder.transform(y)\n",
    "    \n",
    "    return (X, encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d0a9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000,)\n",
      "(6000,)\n"
     ]
    }
   ],
   "source": [
    "alpha = collect_and_label(\"C:/Users/Pushpam/Downloads/ptbxl_database.csv\")  \n",
    "gamma0, gamma1 = div_and_label(alpha)\n",
    "gamma0 = gamma0[:,1]\n",
    "\n",
    "print(gamma0.shape)\n",
    "print(gamma1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ece4cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['records500/05000/05780_hr' 'records500/08000/08511_hr'\n",
      " 'records500/02000/02452_hr' ... 'records500/18000/18091_hr'\n",
      " 'records500/16000/16049_hr' 'records500/07000/07602_hr']\n"
     ]
    }
   ],
   "source": [
    "print(gamma0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e58ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "773322ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "117aa312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import butter, filtfilt, detrend\n",
    "\n",
    "directory = 'D:/Internship/MIDataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1'\n",
    "\n",
    "X = []\n",
    "for itr in range(gamma0.shape[0]):\n",
    "    record_name = str(gamma0[itr])\n",
    "    \n",
    "    signal, meta_val = wfdb.rdsamp(directory + '/' + record_name)\n",
    "    value = signal.T\n",
    "    ecg_signals = value\n",
    "\n",
    "    X.append(detrend(ecg_signals))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41ebc71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 12, 5000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b671bc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000,)\n"
     ]
    }
   ],
   "source": [
    "y_data = gamma1;\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02f4f0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "757"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_data[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d62fa5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windowing X in xnew\n",
    "\n",
    "xnew = []\n",
    "ynew = []\n",
    "patient_ids = []\n",
    "for i in range(X.shape[0]):\n",
    "    xnew.append(X[i,:,0:1000])\n",
    "    xnew.append(X[i,:,1000:2000])\n",
    "    xnew.append(X[i,:,2000:3000])\n",
    "    xnew.append(X[i,:,3000:4000])\n",
    "    xnew.append(X[i,:,4000:5000])\n",
    "    for j in range(5):\n",
    "        ynew.append(y_data[i])\n",
    "        patient_ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "651f09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew = np.array(xnew)\n",
    "ynew = np.array(ynew)\n",
    "patient_ids = np.array(patient_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30a1f0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 12, 1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15307a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 24, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import coherence\n",
    "from glob import glob\n",
    "import scipy.io as sio\n",
    "import scipy.signal as sig\n",
    "\n",
    "cross_corr_matrices_list = []\n",
    "mae_matrices_list = []\n",
    "rmse_matrices_list = []\n",
    "coherence_matrices_list = []\n",
    "\n",
    "\n",
    "for patient_data in xnew:\n",
    "    cross_corr_matrix = np.zeros((12, 12))\n",
    "    mae_matrix = np.zeros((12, 12))\n",
    "    rmse_matrix = np.zeros((12, 12))\n",
    "    coherence_matrix = np.zeros((12, 12))\n",
    "\n",
    "    \n",
    "    for i in range(12):\n",
    "        for j in range(i, 12):\n",
    "            lead_i = patient_data[i]\n",
    "            lead_j = patient_data[j]\n",
    "            \n",
    "            cross_corr = np.corrcoef(lead_i, lead_j)[0, 1]\n",
    "            \n",
    "            mae = np.mean(np.abs(lead_i - lead_j))\n",
    "            rmse = np.sqrt(np.mean((lead_i - lead_j) ** 2))\n",
    "            \n",
    "            f, coh = coherence(lead_i, lead_j)  \n",
    "            coherence_value = np.mean(coh)  # Storing the average coherence value\n",
    "            \n",
    "            \n",
    "            cross_corr_matrix[i, j] = cross_corr\n",
    "            cross_corr_matrix[j, i] = cross_corr\n",
    "            \n",
    "            mae_matrix[i, j] = mae\n",
    "            mae_matrix[j, i] = mae\n",
    "            \n",
    "            rmse_matrix[i, j] = rmse\n",
    "            rmse_matrix[j, i] = rmse\n",
    "            \n",
    "            coherence_matrix[i, j] = coherence_value\n",
    "            coherence_matrix[j, i] = coherence_value      \n",
    "    \n",
    "    \n",
    "    cross_corr_matrices_list.append(cross_corr_matrix)  \n",
    "    mae_matrices_list.append(mae_matrix)\n",
    "    rmse_matrices_list.append(rmse_matrix)  \n",
    "    coherence_matrices_list.append(coherence_matrix)\n",
    "    \n",
    "def create_K(A_i, B_i, C_i, D_i):\n",
    "    top_row = np.concatenate((A_i, B_i), axis=1)\n",
    "    bottom_row = np.concatenate((C_i, D_i), axis=1)\n",
    "    return np.concatenate((top_row, bottom_row), axis=0)\n",
    "\n",
    "K_matrices=[]\n",
    "for i in range(xnew.shape[0]):\n",
    "    K_i = create_K(cross_corr_matrices_list[i], mae_matrices_list[i], rmse_matrices_list[i], coherence_matrices_list[i])\n",
    "    K_matrices.append(K_i)\n",
    "\n",
    "t = np.array(K_matrices).reshape(xnew.shape[0],24,24,1)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ddb5722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cb5ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rocket=Rocket()\n",
    "rocket=Rocket(num_kernels=500)\n",
    "rocket.fit(xnew)\n",
    "xt=rocket.transform(xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f47bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f0f527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(xt, ynew,\n",
    "#                                                     test_size=0.3,\n",
    "#                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fffbcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier=SGDClassifier()\n",
    "# classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11d00a84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 25s 20ms/step - loss: 0.3604 - accuracy: 0.8359 - val_loss: 0.3566 - val_accuracy: 0.8508\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.3156 - accuracy: 0.8603 - val_loss: 0.3163 - val_accuracy: 0.8733\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.3049 - accuracy: 0.8694 - val_loss: 0.3265 - val_accuracy: 0.8623\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.2919 - accuracy: 0.8743 - val_loss: 0.3123 - val_accuracy: 0.8773\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.2918 - accuracy: 0.8757 - val_loss: 0.3352 - val_accuracy: 0.8667\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.2904 - accuracy: 0.8776 - val_loss: 0.3270 - val_accuracy: 0.8669\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.2901 - accuracy: 0.8782 - val_loss: 0.3383 - val_accuracy: 0.8725\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 23s 19ms/step - loss: 0.2885 - accuracy: 0.8772 - val_loss: 0.3392 - val_accuracy: 0.8642\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 23s 19ms/step - loss: 0.2887 - accuracy: 0.8780 - val_loss: 0.3500 - val_accuracy: 0.8660\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 23s 19ms/step - loss: 0.2879 - accuracy: 0.8803 - val_loss: 0.3448 - val_accuracy: 0.8615\n",
      "188/188 [==============================] - 1s 4ms/step\n",
      "[[236  68]\n",
      " [104 792]]\n",
      "0.8566666666666667\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 23s 19ms/step - loss: 0.3612 - accuracy: 0.8360 - val_loss: 0.3258 - val_accuracy: 0.8612\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 23s 19ms/step - loss: 0.3217 - accuracy: 0.8566 - val_loss: 0.3345 - val_accuracy: 0.8640\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 23s 20ms/step - loss: 0.3122 - accuracy: 0.8643 - val_loss: 0.3246 - val_accuracy: 0.8706\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 23s 20ms/step - loss: 0.3016 - accuracy: 0.8701 - val_loss: 0.3353 - val_accuracy: 0.8660\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 23s 20ms/step - loss: 0.2929 - accuracy: 0.8755 - val_loss: 0.3732 - val_accuracy: 0.8735\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 23s 19ms/step - loss: 0.2930 - accuracy: 0.8744 - val_loss: 0.3211 - val_accuracy: 0.8710\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 23s 19ms/step - loss: 0.2856 - accuracy: 0.8794 - val_loss: 0.2938 - val_accuracy: 0.8771\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 23s 19ms/step - loss: 0.2877 - accuracy: 0.8777 - val_loss: 0.3544 - val_accuracy: 0.8783\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.2865 - accuracy: 0.8814 - val_loss: 0.3358 - val_accuracy: 0.8740\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.2870 - accuracy: 0.8814 - val_loss: 0.3203 - val_accuracy: 0.8610\n",
      "188/188 [==============================] - 1s 4ms/step\n",
      "[[133 175]\n",
      " [ 16 876]]\n",
      "0.8408333333333333\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.6070 - accuracy: 0.7503 - val_loss: 0.5778 - val_accuracy: 0.7385\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.5625 - accuracy: 0.7513 - val_loss: 0.5746 - val_accuracy: 0.7385\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.5610 - accuracy: 0.7513 - val_loss: 0.5751 - val_accuracy: 0.7385\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.5609 - accuracy: 0.7513 - val_loss: 0.5752 - val_accuracy: 0.7385\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.5609 - accuracy: 0.7513 - val_loss: 0.5749 - val_accuracy: 0.7385\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.5609 - accuracy: 0.7513 - val_loss: 0.5751 - val_accuracy: 0.7385\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.5609 - accuracy: 0.7513 - val_loss: 0.5750 - val_accuracy: 0.7385\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.5609 - accuracy: 0.7513 - val_loss: 0.5750 - val_accuracy: 0.7385\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.5609 - accuracy: 0.7513 - val_loss: 0.5753 - val_accuracy: 0.7385\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.5610 - accuracy: 0.7513 - val_loss: 0.5750 - val_accuracy: 0.7385\n",
      "188/188 [==============================] - 1s 4ms/step\n",
      "[[  0 294]\n",
      " [  0 906]]\n",
      "0.755\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 23s 19ms/step - loss: 0.3650 - accuracy: 0.8351 - val_loss: 0.3366 - val_accuracy: 0.8460\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.3238 - accuracy: 0.8565 - val_loss: 0.3341 - val_accuracy: 0.8537\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.3094 - accuracy: 0.8655 - val_loss: 0.3263 - val_accuracy: 0.8662\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.3043 - accuracy: 0.8689 - val_loss: 0.3830 - val_accuracy: 0.8400\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.3023 - accuracy: 0.8706 - val_loss: 0.3211 - val_accuracy: 0.8619\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.3011 - accuracy: 0.8726 - val_loss: 0.3257 - val_accuracy: 0.8696\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.2976 - accuracy: 0.8744 - val_loss: 0.3864 - val_accuracy: 0.8633\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.2975 - accuracy: 0.8755 - val_loss: 0.3602 - val_accuracy: 0.8562\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.2920 - accuracy: 0.8787 - val_loss: 0.3157 - val_accuracy: 0.8690\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.2934 - accuracy: 0.8805 - val_loss: 0.3264 - val_accuracy: 0.8704\n",
      "188/188 [==============================] - 1s 4ms/step\n",
      "[[211 102]\n",
      " [ 33 854]]\n",
      "0.8875\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 24s 20ms/step - loss: 0.6078 - accuracy: 0.7514 - val_loss: 0.5911 - val_accuracy: 0.7229\n",
      "Epoch 2/10\n",
      "  37/1200 [..............................] - ETA: 21s - loss: 0.5631 - accuracy: 0.7551"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 45\u001b[0m\n\u001b[0;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBinaryCrossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     42\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     43\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 45\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     54\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(predictions)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Only Relational Features Accuracy\n",
    "\n",
    "from tensorflow.keras.layers import Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D, AvgPool2D\n",
    "# Group-k-fold\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "sum_accuracy = 0\n",
    "for train_idx, test_idx in gkf.split(t, ynew, groups=patient_ids):\n",
    "    X_train, X_test = t[train_idx], t[test_idx]\n",
    "    y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(30, (3, 3), input_shape=(24, 24, 1)))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='BinaryCrossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "                    batch_size=16,\n",
    "                    epochs=10,\n",
    "                    verbose=1, \n",
    "                    validation_split=0.2)\n",
    "\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(predictions).astype(int).transpose()\n",
    "    y_pred = y_pred[0]\n",
    "\n",
    "    y_pred_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_pred_majority.append(majority_vote)\n",
    "\n",
    "    y_test_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_test_majority.append(majority_vote)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "    sum_accuracy += accuracy\n",
    "    print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "    print(accuracy)\n",
    "\n",
    "average_accuracy = sum_accuracy / 5\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ade414d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 12, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xnew).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "226b140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[221  83]\n",
      " [ 26 870]]\n",
      "0.9091666666666667\n",
      "[[187 121]\n",
      " [  7 885]]\n",
      "0.8933333333333333\n",
      "[[285   9]\n",
      " [191 715]]\n",
      "0.8333333333333334\n",
      "[[298  15]\n",
      " [155 732]]\n",
      "0.8583333333333333\n",
      "[[130 151]\n",
      " [  3 916]]\n",
      "0.8716666666666667\n",
      "Average Accuracy: 0.8731666666666668\n"
     ]
    }
   ],
   "source": [
    "# Only Rocket Features Accuracy\n",
    "\n",
    "# Group-k-fold\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GroupKFold\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "sum_accuracy = 0\n",
    "for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "    X_train, X_test = xt.iloc[train_idx], xt.iloc[test_idx]\n",
    "    y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    y_pred_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_pred_majority.append(majority_vote)\n",
    "\n",
    "    y_test_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_test_majority.append(majority_vote)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "    sum_accuracy += accuracy\n",
    "    print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "    print(accuracy)\n",
    "\n",
    "average_accuracy = sum_accuracy / 5\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f24ee97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 312)\n"
     ]
    }
   ],
   "source": [
    "def extract_upper_triangular(matrix):\n",
    "    n = len(matrix)\n",
    "    upper_triangular_array = []\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            upper_triangular_array.append(matrix[i][j])\n",
    "\n",
    "    return upper_triangular_array\n",
    "\n",
    "def concatenate_upper_triangular_vectors(matrix1, matrix2, matrix3, matrix4):\n",
    "    vector1 = extract_upper_triangular(matrix1)\n",
    "    vector2 = extract_upper_triangular(matrix2)\n",
    "    vector3 = extract_upper_triangular(matrix3)\n",
    "    vector4 = extract_upper_triangular(matrix4)\n",
    "\n",
    "    concatenated_vector = vector1 + vector2 + vector3 + vector4\n",
    "    return concatenated_vector\n",
    "\n",
    "t2=[]\n",
    "for i in range(xnew.shape[0]):\n",
    "    K_i = concatenate_upper_triangular_vectors(cross_corr_matrices_list[i], mae_matrices_list[i], rmse_matrices_list[i], coherence_matrices_list[i])\n",
    "    t2.append(K_i)\n",
    "t2 = np.array(t2)\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3bab5dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183 121]\n",
      " [  6 890]]\n",
      "0.8941666666666667\n",
      "[[264  44]\n",
      " [ 61 831]]\n",
      "0.9125\n",
      "[[289   5]\n",
      " [218 688]]\n",
      "0.8141666666666667\n",
      "[[227  86]\n",
      " [ 12 875]]\n",
      "0.9183333333333333\n",
      "[[247  34]\n",
      " [ 76 843]]\n",
      "0.9083333333333333\n",
      "Average Accuracy: 0.8895000000000002\n"
     ]
    }
   ],
   "source": [
    "# Rocket features + Relational features\n",
    "\n",
    "x_all = np.concatenate((xt,t2), axis=1)\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "\n",
    "sum_accuracy = 0\n",
    "for train_idx, test_idx in gkf.split(x_all, ynew, groups=patient_ids):\n",
    "    X_train, X_test = x_all[train_idx], x_all[test_idx]\n",
    "    y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    y_pred_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_pred_majority.append(majority_vote)\n",
    "\n",
    "    y_test_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_test_majority.append(majority_vote)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "    sum_accuracy += accuracy\n",
    "    print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "    print(accuracy)\n",
    "\n",
    "average_accuracy = sum_accuracy / 5\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# sum_accuracy = 0\n",
    "# for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "#     X_train, X_test = xt.iloc[train_idx], xt.iloc[test_idx]\n",
    "#     y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "#     # Use SVC instead of SGDClassifier\n",
    "#     classifier = SVC(kernel='linear', C=1.0)\n",
    "#     classifier.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = classifier.predict(X_test)\n",
    "\n",
    "#     y_pred_majority = []\n",
    "#     for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "#         segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "#         majority_vote = np.bincount(segment_predictions).argmax()\n",
    "#         y_pred_majority.append(majority_vote)\n",
    "\n",
    "#     y_test_majority = []\n",
    "#     for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "#         segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "#         majority_vote = np.bincount(segment_predictions).argmax()\n",
    "#         y_test_majority.append(majority_vote)\n",
    "\n",
    "#     accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "#     sum_accuracy += accuracy\n",
    "#     print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "#     print(accuracy)\n",
    "\n",
    "# average_accuracy = sum_accuracy / 5\n",
    "# print(\"Average Accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# sum_accuracy = 0\n",
    "# for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "#     X_train, X_test = xt.iloc[train_idx], xt.iloc[test_idx]\n",
    "#     y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "#     # Use RandomForestClassifier instead of SGDClassifier\n",
    "#     classifier = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "#     classifier.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = classifier.predict(X_test)\n",
    "\n",
    "#     y_pred_majority = []\n",
    "#     for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "#         segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "#         majority_vote = np.bincount(segment_predictions).argmax()\n",
    "#         y_pred_majority.append(majority_vote)\n",
    "\n",
    "#     y_test_majority = []\n",
    "#     for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "#         segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "#         majority_vote = np.bincount(segment_predictions).argmax()\n",
    "#         y_test_majority.append(majority_vote)\n",
    "\n",
    "#     accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "#     sum_accuracy += accuracy\n",
    "#     print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "#     print(accuracy)\n",
    "\n",
    "# average_accuracy = sum_accuracy / 5\n",
    "# print(\"Average Accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# sum_accuracy = 0\n",
    "# for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "#     X_train, X_test = xt.iloc[train_idx], xt.iloc[test_idx]\n",
    "#     y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "#     # Use KNN classifier instead of SGDClassifier\n",
    "#     classifier = KNeighborsClassifier(n_neighbors=301)  # You can set the number of neighbors here\n",
    "#     classifier.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = classifier.predict(X_test)\n",
    "\n",
    "#     y_pred_majority = []\n",
    "#     for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "#         segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "#         majority_vote = np.bincount(segment_predictions).argmax()\n",
    "#         y_pred_majority.append(majority_vote)\n",
    "\n",
    "#     y_test_majority = []\n",
    "#     for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "#         segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "#         majority_vote = np.bincount(segment_predictions).argmax()\n",
    "#         y_test_majority.append(majority_vote)\n",
    "\n",
    "#     accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "#     sum_accuracy += accuracy\n",
    "#     print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "#     print(accuracy)\n",
    "\n",
    "# average_accuracy = sum_accuracy / 5\n",
    "# print(\"Average Accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b9994",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(ynew[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "212b1f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.6121 - accuracy: 0.7887 - val_loss: 0.3642 - val_accuracy: 0.8250\n",
      "Epoch 2/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3237 - accuracy: 0.8558 - val_loss: 0.2936 - val_accuracy: 0.8783\n",
      "Epoch 3/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2886 - accuracy: 0.8746 - val_loss: 0.3234 - val_accuracy: 0.8607\n",
      "Epoch 4/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2734 - accuracy: 0.8831 - val_loss: 0.3003 - val_accuracy: 0.8965\n",
      "Epoch 5/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2642 - accuracy: 0.8877 - val_loss: 0.2864 - val_accuracy: 0.8885\n",
      "Epoch 6/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2530 - accuracy: 0.8896 - val_loss: 0.2795 - val_accuracy: 0.8868\n",
      "Epoch 7/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2461 - accuracy: 0.8948 - val_loss: 0.2813 - val_accuracy: 0.8783\n",
      "Epoch 8/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2399 - accuracy: 0.8988 - val_loss: 0.2319 - val_accuracy: 0.9043\n",
      "Epoch 9/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2371 - accuracy: 0.9005 - val_loss: 0.3474 - val_accuracy: 0.8735\n",
      "Epoch 10/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2261 - accuracy: 0.9034 - val_loss: 0.2264 - val_accuracy: 0.9073\n",
      "Epoch 11/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2295 - accuracy: 0.9039 - val_loss: 0.2290 - val_accuracy: 0.9023\n",
      "Epoch 12/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2222 - accuracy: 0.9076 - val_loss: 0.2295 - val_accuracy: 0.9070\n",
      "Epoch 13/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2204 - accuracy: 0.9085 - val_loss: 0.2629 - val_accuracy: 0.8930\n",
      "Epoch 14/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2197 - accuracy: 0.9081 - val_loss: 0.3122 - val_accuracy: 0.9087\n",
      "Epoch 15/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2130 - accuracy: 0.9108 - val_loss: 0.2353 - val_accuracy: 0.9082\n",
      "188/188 [==============================] - 0s 687us/step\n",
      "[[216  88]\n",
      " [ 19 877]]\n",
      "0.9108333333333334\n",
      "Epoch 1/15\n",
      "900/900 [==============================] - 2s 1ms/step - loss: 0.5823 - accuracy: 0.7928 - val_loss: 0.2778 - val_accuracy: 0.8803\n",
      "Epoch 2/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3228 - accuracy: 0.8608 - val_loss: 0.4134 - val_accuracy: 0.8267\n",
      "Epoch 3/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2913 - accuracy: 0.8711 - val_loss: 0.2487 - val_accuracy: 0.8967\n",
      "Epoch 4/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2773 - accuracy: 0.8804 - val_loss: 0.3362 - val_accuracy: 0.8687\n",
      "Epoch 5/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2646 - accuracy: 0.8862 - val_loss: 0.3849 - val_accuracy: 0.8628\n",
      "Epoch 6/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2586 - accuracy: 0.8892 - val_loss: 0.2871 - val_accuracy: 0.8667\n",
      "Epoch 7/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.8917 - val_loss: 0.3288 - val_accuracy: 0.8773\n",
      "Epoch 8/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2456 - accuracy: 0.8942 - val_loss: 0.2391 - val_accuracy: 0.8990\n",
      "Epoch 9/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2471 - accuracy: 0.8976 - val_loss: 0.2717 - val_accuracy: 0.8875\n",
      "Epoch 10/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2412 - accuracy: 0.9001 - val_loss: 0.2542 - val_accuracy: 0.8987\n",
      "Epoch 11/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2296 - accuracy: 0.9019 - val_loss: 0.2604 - val_accuracy: 0.9052\n",
      "Epoch 12/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2314 - accuracy: 0.9023 - val_loss: 0.2420 - val_accuracy: 0.9000\n",
      "Epoch 13/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2266 - accuracy: 0.9003 - val_loss: 0.2919 - val_accuracy: 0.8832\n",
      "Epoch 14/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2257 - accuracy: 0.9038 - val_loss: 0.2246 - val_accuracy: 0.9095\n",
      "Epoch 15/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2221 - accuracy: 0.9073 - val_loss: 0.2656 - val_accuracy: 0.8933\n",
      "188/188 [==============================] - 0s 704us/step\n",
      "[[286  22]\n",
      " [100 792]]\n",
      "0.8983333333333333\n",
      "Epoch 1/15\n",
      "900/900 [==============================] - 2s 1ms/step - loss: 0.5483 - accuracy: 0.7884 - val_loss: 0.3353 - val_accuracy: 0.8492\n",
      "Epoch 2/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3226 - accuracy: 0.8600 - val_loss: 0.3112 - val_accuracy: 0.8647\n",
      "Epoch 3/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2931 - accuracy: 0.8726 - val_loss: 0.2644 - val_accuracy: 0.8857\n",
      "Epoch 4/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2764 - accuracy: 0.8790 - val_loss: 0.3351 - val_accuracy: 0.8465\n",
      "Epoch 5/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2659 - accuracy: 0.8888 - val_loss: 0.2385 - val_accuracy: 0.9067\n",
      "Epoch 6/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2648 - accuracy: 0.8874 - val_loss: 0.2833 - val_accuracy: 0.8870\n",
      "Epoch 7/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2536 - accuracy: 0.8954 - val_loss: 0.2339 - val_accuracy: 0.9022\n",
      "Epoch 8/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2457 - accuracy: 0.8956 - val_loss: 0.2516 - val_accuracy: 0.8993\n",
      "Epoch 9/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2409 - accuracy: 0.8996 - val_loss: 0.3222 - val_accuracy: 0.8920\n",
      "Epoch 10/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2333 - accuracy: 0.9015 - val_loss: 0.2474 - val_accuracy: 0.9037\n",
      "Epoch 11/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2345 - accuracy: 0.9021 - val_loss: 0.3006 - val_accuracy: 0.8860\n",
      "Epoch 12/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2267 - accuracy: 0.9029 - val_loss: 0.2223 - val_accuracy: 0.9080\n",
      "Epoch 13/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2240 - accuracy: 0.9066 - val_loss: 0.2256 - val_accuracy: 0.9007\n",
      "Epoch 14/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2204 - accuracy: 0.9097 - val_loss: 0.2307 - val_accuracy: 0.9095\n",
      "Epoch 15/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2137 - accuracy: 0.9114 - val_loss: 0.2879 - val_accuracy: 0.9088\n",
      "188/188 [==============================] - 0s 680us/step\n",
      "[[219  75]\n",
      " [ 38 868]]\n",
      "0.9058333333333334\n",
      "Epoch 1/15\n",
      "900/900 [==============================] - 2s 1ms/step - loss: 0.6081 - accuracy: 0.7845 - val_loss: 0.3411 - val_accuracy: 0.8547\n",
      "Epoch 2/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3305 - accuracy: 0.8511 - val_loss: 0.2723 - val_accuracy: 0.8865\n",
      "Epoch 3/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2977 - accuracy: 0.8744 - val_loss: 0.2871 - val_accuracy: 0.8732\n",
      "Epoch 4/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2804 - accuracy: 0.8828 - val_loss: 0.2937 - val_accuracy: 0.8833\n",
      "Epoch 5/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2685 - accuracy: 0.8876 - val_loss: 0.2422 - val_accuracy: 0.8953\n",
      "Epoch 6/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2573 - accuracy: 0.8897 - val_loss: 0.3725 - val_accuracy: 0.8665\n",
      "Epoch 7/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2554 - accuracy: 0.8902 - val_loss: 0.3260 - val_accuracy: 0.8690\n",
      "Epoch 8/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2526 - accuracy: 0.8901 - val_loss: 0.3289 - val_accuracy: 0.8533\n",
      "Epoch 9/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2520 - accuracy: 0.8957 - val_loss: 0.2442 - val_accuracy: 0.8977\n",
      "Epoch 10/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2444 - accuracy: 0.8981 - val_loss: 0.2538 - val_accuracy: 0.9053\n",
      "Epoch 11/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2425 - accuracy: 0.8964 - val_loss: 0.2438 - val_accuracy: 0.8995\n",
      "Epoch 12/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2380 - accuracy: 0.9011 - val_loss: 0.3127 - val_accuracy: 0.8640\n",
      "Epoch 13/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2325 - accuracy: 0.9028 - val_loss: 0.2400 - val_accuracy: 0.9113\n",
      "Epoch 14/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2288 - accuracy: 0.9054 - val_loss: 0.2572 - val_accuracy: 0.9065\n",
      "Epoch 15/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2247 - accuracy: 0.9052 - val_loss: 0.2313 - val_accuracy: 0.9093\n",
      "188/188 [==============================] - 0s 666us/step\n",
      "[[252  61]\n",
      " [ 24 863]]\n",
      "0.9291666666666667\n",
      "Epoch 1/15\n",
      "900/900 [==============================] - 2s 1ms/step - loss: 0.5670 - accuracy: 0.7961 - val_loss: 0.3215 - val_accuracy: 0.8678\n",
      "Epoch 2/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3196 - accuracy: 0.8579 - val_loss: 0.3005 - val_accuracy: 0.8545\n",
      "Epoch 3/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2907 - accuracy: 0.8745 - val_loss: 0.2928 - val_accuracy: 0.8663\n",
      "Epoch 4/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2753 - accuracy: 0.8793 - val_loss: 0.2973 - val_accuracy: 0.8837\n",
      "Epoch 5/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2615 - accuracy: 0.8864 - val_loss: 0.2368 - val_accuracy: 0.9040\n",
      "Epoch 6/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2569 - accuracy: 0.8893 - val_loss: 0.2428 - val_accuracy: 0.8980\n",
      "Epoch 7/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2499 - accuracy: 0.8932 - val_loss: 0.2848 - val_accuracy: 0.8743\n",
      "Epoch 8/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2410 - accuracy: 0.8972 - val_loss: 0.2583 - val_accuracy: 0.8883\n",
      "Epoch 9/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2435 - accuracy: 0.8987 - val_loss: 0.2327 - val_accuracy: 0.8997\n",
      "Epoch 10/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2402 - accuracy: 0.8980 - val_loss: 0.3171 - val_accuracy: 0.8828\n",
      "Epoch 11/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2334 - accuracy: 0.9002 - val_loss: 0.2666 - val_accuracy: 0.8848\n",
      "Epoch 12/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2345 - accuracy: 0.9024 - val_loss: 0.2468 - val_accuracy: 0.9063\n",
      "Epoch 13/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2277 - accuracy: 0.8994 - val_loss: 0.2520 - val_accuracy: 0.8892\n",
      "Epoch 14/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2282 - accuracy: 0.9065 - val_loss: 0.3123 - val_accuracy: 0.8915\n",
      "Epoch 15/15\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2251 - accuracy: 0.9077 - val_loss: 0.2311 - val_accuracy: 0.9125\n",
      "188/188 [==============================] - 0s 686us/step\n",
      "[[236  45]\n",
      " [ 65 854]]\n",
      "0.9083333333333333\n",
      "Average Accuracy: 0.9105000000000001\n"
     ]
    }
   ],
   "source": [
    "# # # Using DNN for Rocket Features\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(xt, ynew, test_size=0.3, random_state=42)\n",
    "\n",
    "# K.clear_session()\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# # model.add(Conv2D(30, (3, 3)))\n",
    "# # model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# # model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(256, activation='relu')) \n",
    "# model.add(Dense(128, activation='relu')) \n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(loss='BinaryCrossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size=20, epochs=20, verbose=1, \n",
    "#           validation_split=0.25)\n",
    "\n",
    "# model.evaluate(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "sum_accuracy = 0\n",
    "for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "    X_train, X_test = xt.iloc[train_idx], xt.iloc[test_idx]\n",
    "    y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "    \n",
    "    K.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # model.add(Conv2D(30, (3, 3)))\n",
    "    # model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    # model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='BinaryCrossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=20, epochs=15, verbose=1, \n",
    "              validation_split=0.25)\n",
    "\n",
    "#     model.evaluate(X_test, y_test)\n",
    "    \n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.round(y_pred > 0.5 ).astype(int).transpose()\n",
    "    y_pred = y_pred[0]\n",
    "    \n",
    "    y_pred_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_pred_majority.append(majority_vote)\n",
    "\n",
    "    y_test_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_test_majority.append(majority_vote)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "    sum_accuracy += accuracy\n",
    "    print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "    print(accuracy)\n",
    "\n",
    "average_accuracy = sum_accuracy / 5\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a677c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Flatten, Activation\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# import tensorflow.keras.backend as K\n",
    "# from tensorflow.keras.layers import Conv2D\n",
    "# from tensorflow.keras.layers import MaxPool2D, AvgPool2D\n",
    "\n",
    "\n",
    "# # Group-k-fold\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # class SilentHistory(tf.keras.callbacks.Callback):\n",
    "# #     def on_epoch_end(self, epoch, logs=None):\n",
    "# #         pass\n",
    "\n",
    "# gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# sum_accuracy = 0\n",
    "# for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "#     X_train, X_test = xt.iloc[train_idx], xt.iloc[test_idx]\n",
    "#     y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "#     K.clear_session()\n",
    "\n",
    "\n",
    "#     model = Sequential()\n",
    "\n",
    "# #     model.add(Conv2D(10, (3, 3), input_shape=(24, 24, 1)))\n",
    "# #     model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# #     model.add(Flatten())\n",
    "\n",
    "# #     model.add(Dense(1000, activation='relu'))\n",
    "#     model.add(Dense(150, activation='relu')) \n",
    "#     model.add(Dense(100, activation='relu'))\n",
    "#     model.add(Dense(50, activation='relu')) \n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#     model.compile(loss='BinaryCrossentropy',\n",
    "#                   optimizer='rmsprop',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "# #     y_train = np.reshape(y_train, (-1, 1))\n",
    "# #     print(y_train.shape)\n",
    "# #     print(X_train.shape)\n",
    "    \n",
    "# #     history = \n",
    "#     model.fit(X_train, y_train,\n",
    "#                     batch_size=60,\n",
    "#                     epochs=20,\n",
    "#                     verbose=1,  # Set verbose to 0 to suppress epoch logging\n",
    "#                     validation_split=0.25)\n",
    "# #                     callbacks=[SilentHistory()])\n",
    "    \n",
    "#     predictions = model.predict(X_test)\n",
    "#     y_pred = np.round(predictions>0.5).astype(int).transpose()\n",
    "# #     print(y_pred)\n",
    "#     y_pred = y_pred[0]\n",
    "# #     print(y_pred[0,0:10])\n",
    "\n",
    "#     y_pred_majority = []\n",
    "#     for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "#         segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "#         majority_vote = np.bincount(segment_predictions).argmax()\n",
    "#         y_pred_majority.append(majority_vote)\n",
    "\n",
    "#     y_test_majority = []\n",
    "#     for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "#         segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "#         majority_vote = np.bincount(segment_predictions).argmax()\n",
    "#         y_test_majority.append(majority_vote)\n",
    "\n",
    "#     accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "#     sum_accuracy += accuracy\n",
    "#     print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "#     print(accuracy)\n",
    "\n",
    "# average_accuracy = sum_accuracy / 5\n",
    "# print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb1920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.model_selection import KFold\n",
    "# kf=KFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2fa90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum=0\n",
    "# for tr_idx, test_idx in kf.split(xt):\n",
    "#     X_train, X_test=xt.iloc[tr_idx,:],xt.iloc[test_idx,:]\n",
    "#     y_train, y_test=ynew[tr_idx],ynew[test_idx]\n",
    "\n",
    "#     classifier=SGDClassifier()\n",
    "#     classifier.fit(X_train,y_train)\n",
    "\n",
    "#     y_pred=classifier.predict(X_test)\n",
    "#     y_pred_majority = []\n",
    "#     for i in range(0, y_data.shape[0], 5):\n",
    "#         segment_predictions = y_pred[i:i+5]\n",
    "#         majority_vote = np.bincount(segment_predictions).argmax()\n",
    "#         y_pred_majority.append(majority_vote)\n",
    "        \n",
    "#     y_test_majority = []\n",
    "#     for i in range(0, y_data.shape[0], 5):\n",
    "#         segment_predictions = y_test[i:i+5]\n",
    "#         majority_vote = np.bincount(segment_predictions).argmax()\n",
    "#         y_test_majority.append(majority_vote)    \n",
    "    \n",
    "#     sum=sum+accuracy_score(y_test_majority,y_pred_majority)\n",
    "#     print(confusion_matrix(y_test_majority,y_pred_majority))\n",
    "#     print(accuracy_score(y_test_majority,y_pred_majority))\n",
    "# print(sum/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum=0\n",
    "# for tr_idx, test_idx in kf.split(xt):\n",
    "#     X_train, X_test=xt.iloc[tr_idx,:],xt.iloc[test_idx,:]\n",
    "#     y_train, y_test=y_data[tr_idx],y_data[test_idx]\n",
    "\n",
    "#     classifier=SGDClassifier()\n",
    "#     classifier.fit(X_train,y_train)\n",
    "\n",
    "#     ypred=classifier.predict(X_test)\n",
    "#     sum=sum+accuracy_score(y_test,ypred)\n",
    "#     print(confusion_matrix(y_test,ypred))\n",
    "#     print(accuracy_score(y_test,ypred))\n",
    "# print(sum/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc14e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0295a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_majority = []\n",
    "# for i in range(0, y_data.shape[0], 5):\n",
    "#     segment_predictions = y_pred[i:i+5]\n",
    "#     majority_vote = np.bincount(segment_predictions).argmax()\n",
    "#     y_pred_majority.append(majority_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_majority = []\n",
    "# for i in range(0, y_data.shape[0], 5):\n",
    "#     segment_predictions = y_test[i:i+5]\n",
    "#     majority_vote = np.bincount(segment_predictions).argmax()\n",
    "#     y_test_majority.append(majority_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddccd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c606138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(confusion_matrix(y_test,ypred))\n",
    "# print(accuracy_score(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515baa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78c278d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.array(K_matrices);\n",
    "np.save('relational_features.npy',feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5acf339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_array = np.load('relational_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "096440f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(feature_matrix, loaded_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "046bc25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cross_corr_matrix.npy',np.array(cross_corr_matrices_list))\n",
    "np.save('mae_matrix.npy',np.array(mae_matrices_list))\n",
    "np.save('rmse_matrix.npy',np.array(rmse_matrices_list))\n",
    "np.save('coherence_matrix.npy',np.array(coherence_matrices_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1001ef9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24, 24)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_array.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
